---
title: "SpeechMate"
publishedAt: "2025-01-01"
summary: "Combining models to create a tool to help students with speeches"
images:
  - "/images/projects/project-02/speechmate/speechmate.png"
link: "https://github.com/k-nn-tht/SpeechMate"
---

## Overview

The overall goal was to work with a group of students to create a tool to help students with speeches. We intended to combine an analysis of tone, words, and gestures.

## Key Features

- **Tone Analysis** – Detects volume, pace, and emotional cues in speech.

- **Word Usage Insights** – Identifies filler words, repetitive phrases, and suggests improvements for clarity.

- **Gesture Recognition** – Uses computer vision to track hand movements, posture, and facial expressions.

- **Real-time Feedback** – Offers immediate visual and textual suggestions during or after practice.

## Technologies Used

- **Natural Language Processing (NLP)**: For word usage and tone sentiment analysis (e.g., Python).

- **Speech Processing**: Speech-to-text APIs.

- **Computer Vision**: Google MediaPipe for gesture and facial recognition.

- **Machine Learning Models**: Pretrained models for speech and gesture classification.

## Challenges and Learnings

The team members got caught up in school and many dropped out due to the workload. We had to push through this to create something out of what we had. Finding data on the subject proved to be very tough as well.

## Outcome

We created the base of what we had envisioned, creating and implementing the model part of the tool. This includes the gesture recognition and word analysis.