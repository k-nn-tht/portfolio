---
title: "Yelp Sentiment Analysis on Boba Stores"
publishedAt: "2025-02"
summary: "Finetuning a pretrained tranformer-based LLM on Boba Shop Yelp Reviews using models and dataset from Huggingface"
images:
  - "/images/projects/project-02/Yelp_Boba_Sentiment/distilbert.jpg"
  - "/images/projects/project-02/Yelp_Boba_Sentiment/yelp-graph.png"
link: "https://github.com/k-nn-tht/yelp_sentiment_analysis"
---

## Overview

In this project, I focused on learning different types of finetuning including, head-only, full, and LoRA. The overall goal was to compare inference speed compared to accuracy/performance and determine which is best based on the scenario.

## Technologies Used

- **Hugging Face**: For loading DistilBERT, managing tokenizers, downloading dataset, and applying finetuning strategies (head-only, full, LoRA).
- **Python**: For extracting design tokens and component data directly from the Figma designs.
- **LoRA (Low-Rank Adaptation)**: Efficient parameter-efficient fine-tuning method.
- **Wandb**: For model training vizualizations

## Challenges and Learnings

This projects was a great step in exposing me to more about machine learning and AI. I was able to learn ways to adapt a pretrained model to a specific task using different methods.

## Outcome

I wrote a 1 page paper on my findings and process: [Paper](https://docs.google.com/document/d/17lMNpDXW5ij57yW0dWG7npsoHQIv2vFTRcfbv7QeNl8/edit?usp=sharing), [Github](https://github.com/k-nn-tht/yelp_sentiment_analysis)