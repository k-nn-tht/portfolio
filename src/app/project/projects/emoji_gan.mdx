---
title: "Researching Ways to Optimize GANs on Smaller Datasets"
publishedAt: "2025-06"
summary: "Exploring different methods to improve the output of a GAN on a small dataset"
images:
  - "/images/projects/project-02/emoji_gan/results.png"
link: "https://github.com/k-nn-tht/yelp_sentiment_analysis"
---

## Overview

In this project, my team and I researched different ways we could improve the output of DCGAN by making changes such as data augmentation,
hyperparameter tuning, and architectural changes.


## Core Ideas

- **Data Augmentation**: To expand the small dataset and improve the diversity of generated images
- **Hyperparameter Changes**: Discourages overfitting from the discriminator and improves generalization and training stability
- **Architecture Modifications: Spectral Normalization, Historical Averaging, SN and HA Loss all used to combat vanishing gradients and mode collapse

## Technologies Used

- **PyTorch**: For building and training the DCGAN model, experimenting with architectural changes, and running experiments
- **Python**: For data preprocessing, implementing training loops, and managing experiment workflows
- **Matplotlib**: For visualizing training progress, including generator/discriminator loss curves and generated image outputs

## Challenges and Learnings

This project helped me realize the many methods of improving pretrained models

## Outcome

My team and I wrote a 3 page paper on my findings and process: [Paper](https://docs.google.com/document/d/1jgVSwzoT0fxHXmp_Mc6vN90iN39-_ftjBYRddnElsGQ/edit?tab=t.0)